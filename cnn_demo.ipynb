{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "INUJebIH_3ii",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN Examples\n",
        "\n",
        "#### References\n",
        "* https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f\n",
        "* https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n",
        "* https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/"
      ]
    },
    {
      "metadata": {
        "id": "g6Rgoc5AAhaO",
        "colab_type": "code",
        "outputId": "90f74c98-b0da-47dc-cc78-50f4678c0d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# import libraries and mnist dataset\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D, Dense,Dropout,Flatten\n",
        "import numpy as np\n",
        "\n",
        "batch_size= 128\n",
        "n_classes = 10\n",
        "epochs =12\n",
        "img_rows =28\n",
        "img_cols = 28\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"\n",
        "  Load MNIST data\n",
        "  \"\"\"\n",
        "  (x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
        "  #print(x_train[0], 'train samples')\n",
        "\n",
        "  x_train = x_train.reshape(60000,28,28,1)\n",
        "  x_train=x_train[:1000]\n",
        "  x_test = x_test.reshape(10000,28,28,1)\n",
        "  x_test=x_test[:600]\n",
        "\n",
        "  #print(x_train[0], 'train samples')\n",
        "  print(y_train[0])\n",
        "  \n",
        "  y_train = keras.utils.to_categorical(y_train,n_classes)\n",
        "  y_train =y_train[:1000]\n",
        "  y_test = keras.utils.to_categorical(y_test,n_classes)\n",
        "  y_test=y_test[:600]\n",
        "  print(y_train[0])\n",
        "  return x_train, y_train, x_test, y_test \n",
        "  \"\"\"\n",
        "  Load MNIST data\n",
        "  \"\"\"\n",
        "  (x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
        "  #print(x_train[0], 'train samples')\n",
        "\n",
        "  x_train = x_train.reshape(60000,28,28,1)\n",
        "\n",
        "def train_classifier(x_train, y_train, x_test, y_test):\n",
        "  \"\"\"\n",
        "      Train CNN classifier using MNIST dataset\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train,batch_size=256,epochs=10, verbose=1,validation_data=(x_test, y_test))\n",
        "  \n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  \n",
        "  \n",
        "if __name__==\"__main__\":\n",
        "  x_train, y_train, x_test, y_test  = load_data()\n",
        "  train_classifier(x_train, y_train, x_test, y_test)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Train on 1000 samples, validate on 600 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 12.7040 - acc: 0.1800 - val_loss: 12.4361 - val_acc: 0.1983\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 12.6953 - acc: 0.1890 - val_loss: 10.7245 - val_acc: 0.3083\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 11.4770 - acc: 0.2800 - val_loss: 10.9347 - val_acc: 0.3167\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 10.2878 - acc: 0.3420 - val_loss: 9.5181 - val_acc: 0.3817\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 8.8713 - acc: 0.4210 - val_loss: 7.3950 - val_acc: 0.5050\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 6.5044 - acc: 0.5470 - val_loss: 3.7963 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 4.2547 - acc: 0.6270 - val_loss: 1.8344 - val_acc: 0.7250\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2852 - acc: 0.7930 - val_loss: 0.4508 - val_acc: 0.8683\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4271 - acc: 0.8870 - val_loss: 0.3815 - val_acc: 0.8800\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3733 - acc: 0.8930 - val_loss: 0.3177 - val_acc: 0.9067\n",
            "Test loss: 0.3177008064587911\n",
            "Test accuracy: 0.9066666658719381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}