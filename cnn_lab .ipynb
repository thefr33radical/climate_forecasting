{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "INUJebIH_3ii",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN implemantation on different Datasets with variations. \n",
        "\n",
        "#### References\n",
        "* https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f\n",
        "* https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n",
        "* https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/\n",
        "* https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e"
      ]
    },
    {
      "metadata": {
        "id": "9ibXq43_5h7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Barebone CNN implementation \n",
        "### Dataset : MNIST"
      ]
    },
    {
      "metadata": {
        "id": "g6Rgoc5AAhaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries and mnist dataset\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D, Dense,Dropout,Flatten\n",
        "import numpy as np\n",
        "\n",
        "batch_size= 128\n",
        "n_classes = 10\n",
        "epochs =12\n",
        "img_rows =28\n",
        "img_cols = 28\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"\n",
        "  Load MNIST data\n",
        "  \"\"\"\n",
        "  # Datasets : https://keras.io/datasets/\n",
        "  (x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
        "  #print(x_train[0], 'train samples')\n",
        "\n",
        "  x_train = x_train.reshape(60000,28,28,1)\n",
        "  x_train=x_train[:1000]\n",
        "  x_test = x_test.reshape(10000,28,28,1)\n",
        "  x_test=x_test[:600]\n",
        "\n",
        "  #print(x_train[0], 'train samples')\n",
        "  print(y_train[0])\n",
        "  \n",
        "  y_train = keras.utils.to_categorical(y_train,n_classes)\n",
        "  y_train =y_train[:1000]\n",
        "  y_test = keras.utils.to_categorical(y_test,n_classes)\n",
        "  y_test=y_test[:600]\n",
        "  print(y_train[0])\n",
        "  return x_train, y_train, x_test, y_test \n",
        "  \"\"\"\n",
        "  Load MNIST data\n",
        "  \"\"\"\n",
        "  # Datasets : https://keras.io/datasets/\n",
        "  (x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
        "  #print(x_train[0], 'train samples')\n",
        "\n",
        "  x_train = x_train.reshape(60000,28,28,1)\n",
        "\n",
        "def train_classifier(x_train, y_train, x_test, y_test):\n",
        "  \"\"\"\n",
        "      Train CNN classifier using MNIST dataset\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train , batch_size=256, epochs=10, verbose=1, validation_data = (x_test, y_test))\n",
        "  \n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  \n",
        "  \n",
        "if __name__==\"__main__\":\n",
        "  x_train, y_train, x_test, y_test  = load_data()\n",
        "  train_classifier(x_train, y_train, x_test, y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Fcsf-dX2LYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image classification using custom CNN \n",
        "### Dataset : CIFAR10 with synthetic data augumentation\n"
      ]
    },
    {
      "metadata": {
        "id": "d-UUsnFK262o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras .datasets import cifar10\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"\n",
        "  Function to load dataset\n",
        "  \"\"\"\n",
        "  (x_train, y_train), (x_test,y_test) = cifar10.load_data()\n",
        "  \n",
        "  x_train = x_train.reshape(50000,32,32,3)\n",
        "  x_test = x_test.reshape(10000,32,32,3)\n",
        "  \n",
        "  y_train = keras.utils.to_categorical(y_train,10)\n",
        "  y_test = keras.utils.to_categorical(y_test,10)\n",
        "  \n",
        "  x_train=x_train[:1000]\n",
        "  x_test=x_test[:600]\n",
        "  y_train =y_train[:1000]\n",
        "  y_test=y_test[:600]\n",
        "  return x_train, y_train, x_test, y_test \n",
        "  \n",
        "def train_classifier(x_train, y_train, x_test, y_test):\n",
        "  \"\"\"\n",
        "  Function to train the NN  \n",
        "  \"\"\"\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,activation=\"relu\", padding=\"same\", kernel_size=(3,3),input_shape=(32,32,3)))\n",
        "  # padding : https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n",
        "  model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
        " \n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128,activation=\"relu\"))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(10,activation=\"softmax\"))\n",
        "  \n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\",metrics = [\"accuracy\"])\n",
        "  model.fit(x_train,y_train, validation_data = (x_test,y_test), batch_size=500,epochs=3,verbose=1)\n",
        "  \n",
        "  predict =model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(\" test loss : \", predict[0],\"test accuracy : \",predict[1])\n",
        "    \n",
        "  \n",
        "x_train, y_train, x_test, y_test  = load_data()\n",
        "train_classifier(x_train, y_train, x_test, y_test)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}